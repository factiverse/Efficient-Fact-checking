{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "qUateVGEe9se",
        "outputId": "9cb76983-b200-472d-dfe0-4c45b8b6df95"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, load_from_disk\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import os\n",
        "from optuna.visualization.matplotlib import plot_param_importances\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from setfit import SetFitModel, SetFitTrainer, sample_dataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import BertForSequenceClassification, BertTokenizerFast, get_linear_schedule_with_warmup\n",
        "from tqdm.auto import tqdm\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
        "data_path = os.path.join(dir_path, \"data\", \"wice\")\n",
        "save_dir = os.path.join(dir_path, \"models\", \"setfit\", \"wice_classifier\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Miscellaneous helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "wQMu4yhqe9sh"
      },
      "outputs": [],
      "source": [
        "def binary_indices(row_data: pd.Series) -> List:\n",
        "    \"\"\"\n",
        "    Convert list of indices to list of binary values indicating whether the corresponding\n",
        "    evidence sentence supports or not.\n",
        "\n",
        "    Args:\n",
        "        row_data (Series): row of WiCE dataset to apply changes to.\n",
        "\n",
        "    Returns:\n",
        "        List: list of binary values corresponding to the list of sentences in the 'evidence' column,\n",
        "        where 0's are for 'not support' sentences and 1's for 'support' sentences.\n",
        "    \"\"\"\n",
        "    indices = set(item for sublist in row_data[\"supporting_sentences\"] for item in sublist)\n",
        "    binary_array = [int(i in indices) for i in range(len(row_data[\"evidence\"]))]\n",
        "    return binary_array\n",
        "\n",
        "\n",
        "def prepare_wice_data() -> (pd.DataFrame, pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Loads WiCE train and dev data and formats the data for model training.\n",
        "    Note: train and dev files from `https://github.com/ryokamoi/wice/data/entailment_retrieval/claims`\n",
        "\n",
        "    Returns:\n",
        "        (DataFrame, DataFrame): train and dev dataframes with just the evidence and supporting sentences as columns.\n",
        "    \"\"\"\n",
        "\n",
        "    df_train = pd.read_json(f\"{data_path}/train.jsonl\", lines=True)\n",
        "    df_train[\"label\"] = df_train.apply(binary_indices, axis=1)\n",
        "    df_train.drop([\"supporting_sentences\", \"claim\", \"meta\"], axis=1, inplace=True)\n",
        "\n",
        "    df_dev = pd.read_json(f\"{data_path}/dev.jsonl\", lines=True)\n",
        "    df_dev[\"label\"] = df_dev.apply(binary_indices, axis=1)\n",
        "    df_dev.drop([\"supporting_sentences\", \"claim\", \"meta\"], axis=1, inplace=True)\n",
        "\n",
        "    df_train = df_train.explode([\"label\", \"evidence\"], ignore_index=True)\n",
        "    df_dev = df_dev.explode([\"label\", \"evidence\"], ignore_index=True)\n",
        "\n",
        "    return df_train, df_dev\n",
        "\n",
        "def compute_metrics(labels: List, preds: List) -> Dict:\n",
        "    \"\"\"\n",
        "    Calculates metrics during training and/or evaluation\n",
        "\n",
        "    Args:\n",
        "        labels (List): List of true labels.\n",
        "        preds (List): List of predicted labels.\n",
        "\n",
        "    Returns:\n",
        "        Dict: various metric values\n",
        "    \"\"\"\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary', zero_division=0.0)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "def subsample_train(dataframe: pd.DataFrame):\n",
        "    minority_df = dataframe[dataframe['labels'] == 1]\n",
        "    majority_df = dataframe[dataframe['labels'] == 0]\n",
        "    subsample_major = majority_df.sample(n=5000)\n",
        "    result = pd.concat([minority_df, subsample_major])\n",
        "    result = result.sample(frac=1).reset_index(drop=True)\n",
        "    return Dataset.from_pandas(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SetFit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_init(params: Any, use_setfithead=False):\n",
        "    \"\"\"\n",
        "    Initialises SetFit model with parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    if use_setfithead:\n",
        "        params = {\n",
        "            \"use_differentiable_head\": True,\n",
        "            \"head_params\": {\n",
        "                \"out_features\": 2\n",
        "            }\n",
        "        }\n",
        "    else:\n",
        "        params = params or {}\n",
        "        max_iter = params.get(\"max_iter\", 200)\n",
        "        solver = params.get(\"solver\", \"liblinear\")\n",
        "        params = {\n",
        "            \"head_params\": {\n",
        "                \"max_iter\": max_iter,\n",
        "                \"solver\": solver,\n",
        "            }\n",
        "        }\n",
        "\n",
        "    # Load SetFit Model.\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "    checkpoint = \"sentence-transformers/paraphrase-mpnet-base-v2\"\n",
        "    model = SetFitModel.from_pretrained(checkpoint, **params).to(device=device)\n",
        "    if not use_setfithead:\n",
        "        model.model_head = LogisticRegression(class_weight='balanced')\n",
        "    return model\n",
        "\n",
        "def hp_space(trial: Any):\n",
        "    \"\"\"\n",
        "    Hyperparameter space\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-8, 1e-4, log=True),\n",
        "        \"num_epochs\": trial.suggest_int(\"num_epochs\", 1, 10),\n",
        "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [4, 8, 16, 32]),\n",
        "        \"num_iterations\": trial.suggest_int(\"num_iterations\", 5, 20),\n",
        "        \"max_iter\": trial.suggest_int(\"max_iter\", 50, 500),\n",
        "        \"solver\": trial.suggest_categorical(\"solver\", [\"lbfgs\", \"liblinear\", \"saga\"]),\n",
        "    }\n",
        "\n",
        "def my_objective(metrics: Any) -> Any:\n",
        "    \"\"\"\n",
        "    Objective metric to optimize for\n",
        "\n",
        "    Args:\n",
        "        metrics: metric(s) from which to optimize for\n",
        "    \n",
        "    Returns:\n",
        "        Any: a single metric\n",
        "    \"\"\"\n",
        "    return metrics['f1']\n",
        "\n",
        "def save_run(run: Any) -> None:\n",
        "    \"\"\"\n",
        "    Save BestRun object containing model parameters after hyperparameter tuning as pickle.\n",
        "\n",
        "    Args:\n",
        "        run (Any): setfit BestRun object to store\n",
        "    \"\"\"\n",
        "    with open(f\"{save_dir}/best_run.pkl\", \"wb\") as file:\n",
        "        pickle.dump(run, file)\n",
        "\n",
        "def load_run(file_location=None) -> Any:\n",
        "    \"\"\"\n",
        "    Loads BestRun object containing model parameters for instantiating a SetFitmodel.\n",
        "\n",
        "    Args:\n",
        "        file_location: string containing the file location\n",
        "    \n",
        "    Returns:\n",
        "        Any: setfit BestRun object\n",
        "    \"\"\"\n",
        "    file_location = f\"{save_dir}/best_run.pkl\" if not file_location else file_location\n",
        "    with open(file_location, \"rb\") as file:\n",
        "        return pickle.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setfit_hyperparameter_tuning(n_samples=16) -> None:\n",
        "    \"\"\"\n",
        "    Performs hyperparameter tuning on Setfit\n",
        "\n",
        "    Args:\n",
        "        n_samples (Int): amount of training samples to take per class label\n",
        "    \"\"\"\n",
        "    \n",
        "    train_data, dev_data = prepare_wice_data()\n",
        "    train_dataset_full = Dataset.from_pandas(train_data)\n",
        "    train_dataset_sample = sample_dataset(train_dataset_full, \n",
        "                                          num_samples=n_samples)\n",
        "    val_dataset = Dataset.from_pandas(dev_data)\n",
        "\n",
        "    trainer = SetFitTrainer(\n",
        "        model_init=model_init,\n",
        "        train_dataset=train_dataset_sample,\n",
        "        eval_dataset=val_dataset,\n",
        "        column_mapping={\"evidence\": \"text\", \"label\": \"label\"},\n",
        "        metric=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Perform Hyperparameter tuning\n",
        "    best_run = trainer.hyperparameter_search(direction=\"maximize\", \n",
        "                                             hp_space=hp_space, \n",
        "                                             n_trials=100, \n",
        "                                             compute_objective=my_objective)\n",
        "    print(f\"\\nBest Run: {best_run}\")\n",
        "    plot_param_importances(best_run.backend)\n",
        "\n",
        "    # Store information\n",
        "    save_run(best_run)\n",
        "    train_df = Dataset.to_pandas(train_dataset_sample)\n",
        "    train_df.to_csv(f'{save_dir}/tune_train.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "[I 2023-11-12 11:28:00,975] A new study created in memory with name: no-name-ab0dcdec-d50c-4ccd-9667-ed3e4a74d4c7\n",
            "Trial: {'learning_rate': 2.9161843612039506e-05, 'num_epochs': 5, 'batch_size': 16, 'num_iterations': 10, 'max_iter': 405, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 10/10 [00:00<00:00, 1417.95it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 640\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 200\n",
            "  Total train batch size = 16\n",
            "Iteration: 100%|██████████| 40/40 [00:03<00:00, 12.68it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:03<00:00, 12.57it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:03<00:00, 12.40it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:03<00:00, 12.88it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:03<00:00, 12.66it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:15<00:00,  3.17s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:28:38,474] Trial 0 finished with value: 0.11875705055891704 and parameters: {'learning_rate': 2.9161843612039506e-05, 'num_epochs': 5, 'batch_size': 16, 'num_iterations': 10, 'max_iter': 405, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.11875705055891704.\n",
            "Trial: {'learning_rate': 8.685850960542087e-07, 'num_epochs': 1, 'batch_size': 8, 'num_iterations': 10, 'max_iter': 278, 'solver': 'saga'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 10/10 [00:00<00:00, 1400.39it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 640\n",
            "  Num epochs = 1\n",
            "  Total optimization steps = 80\n",
            "  Total train batch size = 8\n",
            "Iteration: 100%|██████████| 80/80 [00:05<00:00, 13.88it/s]\n",
            "Epoch: 100%|██████████| 1/1 [00:05<00:00,  5.77s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:29:06,034] Trial 1 finished with value: 0.08482805665904257 and parameters: {'learning_rate': 8.685850960542087e-07, 'num_epochs': 1, 'batch_size': 8, 'num_iterations': 10, 'max_iter': 278, 'solver': 'saga'}. Best is trial 0 with value: 0.11875705055891704.\n",
            "Trial: {'learning_rate': 6.194956357983778e-08, 'num_epochs': 2, 'batch_size': 16, 'num_iterations': 6, 'max_iter': 267, 'solver': 'liblinear'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 6/6 [00:00<00:00, 832.86it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 384\n",
            "  Num epochs = 2\n",
            "  Total optimization steps = 48\n",
            "  Total train batch size = 16\n",
            "Iteration: 100%|██████████| 24/24 [00:01<00:00, 12.34it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:01<00:00, 12.20it/s]\n",
            "Epoch: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:29:31,730] Trial 2 finished with value: 0.08472906403940887 and parameters: {'learning_rate': 6.194956357983778e-08, 'num_epochs': 2, 'batch_size': 16, 'num_iterations': 6, 'max_iter': 267, 'solver': 'liblinear'}. Best is trial 0 with value: 0.11875705055891704.\n",
            "Trial: {'learning_rate': 1.0686681104721531e-05, 'num_epochs': 6, 'batch_size': 16, 'num_iterations': 12, 'max_iter': 169, 'solver': 'saga'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 12/12 [00:00<00:00, 1442.37it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 768\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 288\n",
            "  Total train batch size = 16\n",
            "Iteration: 100%|██████████| 48/48 [00:03<00:00, 12.46it/s]\n",
            "Iteration: 100%|██████████| 48/48 [00:03<00:00, 12.59it/s]\n",
            "Iteration: 100%|██████████| 48/48 [00:03<00:00, 12.49it/s]\n",
            "Iteration: 100%|██████████| 48/48 [00:03<00:00, 12.57it/s]\n",
            "Iteration: 100%|██████████| 48/48 [00:03<00:00, 12.51it/s]\n",
            "Iteration: 100%|██████████| 48/48 [00:03<00:00, 12.25it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:23<00:00,  3.85s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:30:16,271] Trial 3 finished with value: 0.10771495367564292 and parameters: {'learning_rate': 1.0686681104721531e-05, 'num_epochs': 6, 'batch_size': 16, 'num_iterations': 12, 'max_iter': 169, 'solver': 'saga'}. Best is trial 0 with value: 0.11875705055891704.\n",
            "Trial: {'learning_rate': 1.0553505818848183e-08, 'num_epochs': 9, 'batch_size': 4, 'num_iterations': 8, 'max_iter': 302, 'solver': 'liblinear'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 8/8 [00:00<00:00, 1233.48it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 512\n",
            "  Num epochs = 9\n",
            "  Total optimization steps = 1152\n",
            "  Total train batch size = 4\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 13.87it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 13.98it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 14.04it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 13.94it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 13.92it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 14.03it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 13.92it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 13.96it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 14.01it/s]\n",
            "Epoch: 100%|██████████| 9/9 [01:22<00:00,  9.17s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:32:00,852] Trial 4 finished with value: 0.08476940751682258 and parameters: {'learning_rate': 1.0553505818848183e-08, 'num_epochs': 9, 'batch_size': 4, 'num_iterations': 8, 'max_iter': 302, 'solver': 'liblinear'}. Best is trial 0 with value: 0.11875705055891704.\n",
            "Trial: {'learning_rate': 2.8490742460668073e-07, 'num_epochs': 2, 'batch_size': 16, 'num_iterations': 13, 'max_iter': 305, 'solver': 'saga'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 13/13 [00:00<00:00, 1341.91it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 832\n",
            "  Num epochs = 2\n",
            "  Total optimization steps = 104\n",
            "  Total train batch size = 16\n",
            "Iteration: 100%|██████████| 52/52 [00:04<00:00, 12.43it/s]\n",
            "Iteration: 100%|██████████| 52/52 [00:04<00:00, 12.28it/s]\n",
            "Epoch: 100%|██████████| 2/2 [00:08<00:00,  4.21s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:32:30,634] Trial 5 finished with value: 0.08463721118767735 and parameters: {'learning_rate': 2.8490742460668073e-07, 'num_epochs': 2, 'batch_size': 16, 'num_iterations': 13, 'max_iter': 305, 'solver': 'saga'}. Best is trial 0 with value: 0.11875705055891704.\n",
            "Trial: {'learning_rate': 4.5124933919276586e-05, 'num_epochs': 2, 'batch_size': 8, 'num_iterations': 16, 'max_iter': 74, 'solver': 'liblinear'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 1389.71it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 2\n",
            "  Total optimization steps = 256\n",
            "  Total train batch size = 8\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 13.80it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 13.68it/s]\n",
            "Epoch: 100%|██████████| 2/2 [00:18<00:00,  9.32s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:33:10,642] Trial 6 finished with value: 0.1236131345959879 and parameters: {'learning_rate': 4.5124933919276586e-05, 'num_epochs': 2, 'batch_size': 8, 'num_iterations': 16, 'max_iter': 74, 'solver': 'liblinear'}. Best is trial 6 with value: 0.1236131345959879.\n",
            "Trial: {'learning_rate': 3.777123020402298e-05, 'num_epochs': 10, 'batch_size': 32, 'num_iterations': 12, 'max_iter': 120, 'solver': 'liblinear'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 12/12 [00:00<00:00, 1426.43it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 768\n",
            "  Num epochs = 10\n",
            "  Total optimization steps = 240\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.48it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.28it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.43it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.38it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.34it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.42it/s]\n",
            "Epoch: 100%|██████████| 10/10 [00:32<00:00,  3.27s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:34:05,062] Trial 7 finished with value: 0.11445189274447948 and parameters: {'learning_rate': 3.777123020402298e-05, 'num_epochs': 10, 'batch_size': 32, 'num_iterations': 12, 'max_iter': 120, 'solver': 'liblinear'}. Best is trial 6 with value: 0.1236131345959879.\n",
            "Trial: {'learning_rate': 4.331259085459799e-08, 'num_epochs': 5, 'batch_size': 8, 'num_iterations': 18, 'max_iter': 374, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 18/18 [00:00<00:00, 1461.97it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1152\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 720\n",
            "  Total train batch size = 8\n",
            "Iteration: 100%|██████████| 144/144 [00:10<00:00, 13.91it/s]\n",
            "Iteration: 100%|██████████| 144/144 [00:10<00:00, 13.83it/s]\n",
            "Iteration: 100%|██████████| 144/144 [00:10<00:00, 13.70it/s]\n",
            "Iteration: 100%|██████████| 144/144 [00:10<00:00, 13.82it/s]\n",
            "Iteration: 100%|██████████| 144/144 [00:10<00:00, 13.67it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:52<00:00, 10.45s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:35:18,672] Trial 8 finished with value: 0.0843799536641873 and parameters: {'learning_rate': 4.331259085459799e-08, 'num_epochs': 5, 'batch_size': 8, 'num_iterations': 18, 'max_iter': 374, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.1236131345959879.\n",
            "Trial: {'learning_rate': 4.805761655642734e-07, 'num_epochs': 9, 'batch_size': 8, 'num_iterations': 9, 'max_iter': 318, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 9/9 [00:00<00:00, 1273.70it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 576\n",
            "  Num epochs = 9\n",
            "  Total optimization steps = 648\n",
            "  Total train batch size = 8\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 14.16it/s]\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 14.17it/s]\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 13.81it/s]\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 14.16it/s]\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 13.84it/s]\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 14.18it/s]\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 14.11it/s]\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 14.25it/s]\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 14.19it/s]\n",
            "Epoch: 100%|██████████| 9/9 [00:46<00:00,  5.11s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:36:26,295] Trial 9 finished with value: 0.09111761449023174 and parameters: {'learning_rate': 4.805761655642734e-07, 'num_epochs': 9, 'batch_size': 8, 'num_iterations': 9, 'max_iter': 318, 'solver': 'lbfgs'}. Best is trial 6 with value: 0.1236131345959879.\n",
            "Trial: {'learning_rate': 4.202193720079208e-06, 'num_epochs': 3, 'batch_size': 4, 'num_iterations': 19, 'max_iter': 496, 'solver': 'liblinear'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 19/19 [00:00<00:00, 1274.38it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1216\n",
            "  Num epochs = 3\n",
            "  Total optimization steps = 912\n",
            "  Total train batch size = 4\n",
            "Iteration: 100%|██████████| 304/304 [00:21<00:00, 14.22it/s]\n",
            "Iteration: 100%|██████████| 304/304 [00:21<00:00, 14.07it/s]\n",
            "Iteration: 100%|██████████| 304/304 [00:21<00:00, 14.04it/s]\n",
            "Epoch: 100%|██████████| 3/3 [01:04<00:00, 21.55s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:37:52,259] Trial 10 finished with value: 0.10653052542012337 and parameters: {'learning_rate': 4.202193720079208e-06, 'num_epochs': 3, 'batch_size': 4, 'num_iterations': 19, 'max_iter': 496, 'solver': 'liblinear'}. Best is trial 6 with value: 0.1236131345959879.\n",
            "Trial: {'learning_rate': 5.0638072434747875e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 450, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 1435.76it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 160\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.38it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.19it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.29it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:21<00:00,  4.39s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:38:35,862] Trial 11 finished with value: 0.12601478250333212 and parameters: {'learning_rate': 5.0638072434747875e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 450, 'solver': 'lbfgs'}. Best is trial 11 with value: 0.12601478250333212.\n",
            "Trial: {'learning_rate': 9.889316319386012e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 55, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 1452.64it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 224\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.19it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.28it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.19it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.16it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:30<00:00,  4.41s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:39:28,552] Trial 12 finished with value: 0.13975625585923415 and parameters: {'learning_rate': 9.889316319386012e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 55, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 8.778343408820452e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 448, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 1265.94it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 224\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.17it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.19it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.15it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:30<00:00,  4.42s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:40:20,902] Trial 13 finished with value: 0.13711583924349882 and parameters: {'learning_rate': 8.778343408820452e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 448, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 9.974940551448343e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 194, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 15/15 [00:00<00:00, 1453.66it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 960\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 210\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.43it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.29it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.31it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.23it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:28<00:00,  4.11s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:41:11,552] Trial 14 finished with value: 0.12063289795051503 and parameters: {'learning_rate': 9.974940551448343e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 194, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 5.6258218108137874e-06, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 20, 'max_iter': 205, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 20/20 [00:00<00:00, 1386.39it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1280\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 280\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 40/40 [00:05<00:00,  7.31it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:05<00:00,  7.46it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:05<00:00,  7.31it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:05<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:05<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:05<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:05<00:00,  7.35it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:38<00:00,  5.46s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:42:11,233] Trial 15 finished with value: 0.10459416798205533 and parameters: {'learning_rate': 5.6258218108137874e-06, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 20, 'max_iter': 205, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 1.0521773417225612e-05, 'num_epochs': 8, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 74, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 14/14 [00:00<00:00, 867.31it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 896\n",
            "  Num epochs = 8\n",
            "  Total optimization steps = 224\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.44it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.31it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.53it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.30it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.32it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.45it/s]\n",
            "Epoch: 100%|██████████| 8/8 [00:30<00:00,  3.80s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:43:03,304] Trial 16 finished with value: 0.10865634784142524 and parameters: {'learning_rate': 1.0521773417225612e-05, 'num_epochs': 8, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 74, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 2.3842825905419392e-06, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 17, 'max_iter': 398, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 17/17 [00:00<00:00, 1456.36it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1088\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 238\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.32it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.32it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.20it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.26it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:32<00:00,  4.66s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:43:57,380] Trial 17 finished with value: 0.1014660647944713 and parameters: {'learning_rate': 2.3842825905419392e-06, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 17, 'max_iter': 398, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 9.141963100257596e-05, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 18, 'max_iter': 236, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 18/18 [00:00<00:00, 1441.73it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1152\n",
            "  Num epochs = 4\n",
            "  Total optimization steps = 144\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.38it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.23it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.21it/s]\n",
            "Epoch: 100%|██████████| 4/4 [00:19<00:00,  4.95s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:44:38,822] Trial 18 finished with value: 0.10628324168394482 and parameters: {'learning_rate': 9.141963100257596e-05, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 18, 'max_iter': 236, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 1.866657036635969e-05, 'num_epochs': 8, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 349, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 14/14 [00:00<00:00, 1334.49it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 896\n",
            "  Num epochs = 8\n",
            "  Total optimization steps = 224\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.43it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.31it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.52it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.30it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.33it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.46it/s]\n",
            "Epoch: 100%|██████████| 8/8 [00:30<00:00,  3.81s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:45:30,672] Trial 19 finished with value: 0.1107266435986159 and parameters: {'learning_rate': 1.866657036635969e-05, 'num_epochs': 8, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 349, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 1.67417997919872e-05, 'num_epochs': 6, 'batch_size': 4, 'num_iterations': 20, 'max_iter': 139, 'solver': 'saga'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 20/20 [00:00<00:00, 1389.21it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1280\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 1920\n",
            "  Total train batch size = 4\n",
            "Iteration: 100%|██████████| 320/320 [00:22<00:00, 13.98it/s]\n",
            "Iteration: 100%|██████████| 320/320 [00:22<00:00, 14.00it/s]\n",
            "Iteration: 100%|██████████| 320/320 [00:22<00:00, 14.31it/s]\n",
            "Iteration: 100%|██████████| 320/320 [00:22<00:00, 14.04it/s]\n",
            "Iteration: 100%|██████████| 320/320 [00:22<00:00, 13.97it/s]\n",
            "Iteration: 100%|██████████| 320/320 [00:22<00:00, 14.29it/s]\n",
            "Epoch: 100%|██████████| 6/6 [02:16<00:00, 22.70s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:48:08,399] Trial 20 finished with value: 0.11185640930748947 and parameters: {'learning_rate': 1.67417997919872e-05, 'num_epochs': 6, 'batch_size': 4, 'num_iterations': 20, 'max_iter': 139, 'solver': 'saga'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 9.732325693274707e-05, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 484, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 1429.61it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 4\n",
            "  Total optimization steps = 128\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.38it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.20it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.27it/s]\n",
            "Epoch: 100%|██████████| 4/4 [00:17<00:00,  4.39s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:48:47,310] Trial 21 finished with value: 0.10776894338538175 and parameters: {'learning_rate': 9.732325693274707e-05, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 484, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 4.342652787435844e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 456, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 1298.40it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 192\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.18it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.29it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.18it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:26<00:00,  4.41s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:49:35,816] Trial 22 finished with value: 0.1226244343891403 and parameters: {'learning_rate': 4.342652787435844e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 456, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 4.7641050706740876e-05, 'num_epochs': 8, 'batch_size': 32, 'num_iterations': 17, 'max_iter': 440, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 17/17 [00:00<00:00, 1379.68it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1088\n",
            "  Num epochs = 8\n",
            "  Total optimization steps = 272\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.34it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.31it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.22it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.28it/s]\n",
            "Epoch: 100%|██████████| 8/8 [00:37<00:00,  4.66s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:50:34,790] Trial 23 finished with value: 0.11320213985479556 and parameters: {'learning_rate': 4.7641050706740876e-05, 'num_epochs': 8, 'batch_size': 32, 'num_iterations': 17, 'max_iter': 440, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 2.306711206637824e-05, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 434, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 14/14 [00:00<00:00, 1401.54it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 896\n",
            "  Num epochs = 4\n",
            "  Total optimization steps = 112\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.43it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.32it/s]\n",
            "Epoch: 100%|██████████| 4/4 [00:15<00:00,  3.82s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:51:11,479] Trial 24 finished with value: 0.1085161175739277 and parameters: {'learning_rate': 2.306711206637824e-05, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 434, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 6.222178602946889e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 18, 'max_iter': 354, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 18/18 [00:00<00:00, 1382.33it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1152\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 180\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.28it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.21it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.41it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:24<00:00,  4.93s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:51:58,018] Trial 25 finished with value: 0.12613035819142687 and parameters: {'learning_rate': 6.222178602946889e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 18, 'max_iter': 354, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 9.252950599362305e-06, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 18, 'max_iter': 358, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 18/18 [00:00<00:00, 1372.43it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1152\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 252\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.38it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.28it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.20it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.42it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.31it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:34<00:00,  4.93s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:52:54,020] Trial 26 finished with value: 0.1050405953991881 and parameters: {'learning_rate': 9.252950599362305e-06, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 18, 'max_iter': 358, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 2.061541160285499e-05, 'num_epochs': 9, 'batch_size': 32, 'num_iterations': 19, 'max_iter': 413, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 19/19 [00:00<00:00, 708.39it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1216\n",
            "  Num epochs = 9\n",
            "  Total optimization steps = 342\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 38/38 [00:05<00:00,  7.34it/s]\n",
            "Iteration: 100%|██████████| 38/38 [00:05<00:00,  7.33it/s]\n",
            "Iteration: 100%|██████████| 38/38 [00:05<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 38/38 [00:05<00:00,  7.23it/s]\n",
            "Iteration: 100%|██████████| 38/38 [00:05<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 38/38 [00:05<00:00,  7.31it/s]\n",
            "Iteration: 100%|██████████| 38/38 [00:05<00:00,  7.33it/s]\n",
            "Iteration: 100%|██████████| 38/38 [00:05<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 38/38 [00:05<00:00,  7.31it/s]\n",
            "Epoch: 100%|██████████| 9/9 [00:46<00:00,  5.22s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:54:02,706] Trial 27 finished with value: 0.11182139108863658 and parameters: {'learning_rate': 2.061541160285499e-05, 'num_epochs': 9, 'batch_size': 32, 'num_iterations': 19, 'max_iter': 413, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 7.703308414623449e-05, 'num_epochs': 6, 'batch_size': 4, 'num_iterations': 15, 'max_iter': 335, 'solver': 'saga'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 15/15 [00:00<00:00, 1449.84it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 960\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 1440\n",
            "  Total train batch size = 4\n",
            "Iteration: 100%|██████████| 240/240 [00:17<00:00, 13.96it/s]\n",
            "Iteration: 100%|██████████| 240/240 [00:17<00:00, 13.99it/s]\n",
            "Iteration: 100%|██████████| 240/240 [00:17<00:00, 14.02it/s]\n",
            "Iteration: 100%|██████████| 240/240 [00:16<00:00, 14.14it/s]\n",
            "Iteration: 100%|██████████| 240/240 [00:16<00:00, 14.23it/s]\n",
            "Iteration: 100%|██████████| 240/240 [00:16<00:00, 14.67it/s]\n",
            "Epoch: 100%|██████████| 6/6 [01:41<00:00, 16.95s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:56:05,895] Trial 28 finished with value: 0.1058591620182024 and parameters: {'learning_rate': 7.703308414623449e-05, 'num_epochs': 6, 'batch_size': 4, 'num_iterations': 15, 'max_iter': 335, 'solver': 'saga'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 2.8447398296646872e-05, 'num_epochs': 5, 'batch_size': 16, 'num_iterations': 17, 'max_iter': 384, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 17/17 [00:00<00:00, 1344.07it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1088\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 340\n",
            "  Total train batch size = 16\n",
            "Iteration: 100%|██████████| 68/68 [00:05<00:00, 12.53it/s]\n",
            "Iteration: 100%|██████████| 68/68 [00:05<00:00, 12.46it/s]\n",
            "Iteration: 100%|██████████| 68/68 [00:05<00:00, 12.48it/s]\n",
            "Iteration: 100%|██████████| 68/68 [00:05<00:00, 12.32it/s]\n",
            "Iteration: 100%|██████████| 68/68 [00:05<00:00, 12.25it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:27<00:00,  5.49s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:56:55,373] Trial 29 finished with value: 0.11295180722891565 and parameters: {'learning_rate': 2.8447398296646872e-05, 'num_epochs': 5, 'batch_size': 16, 'num_iterations': 17, 'max_iter': 384, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 3.0827536132512546e-05, 'num_epochs': 8, 'batch_size': 32, 'num_iterations': 11, 'max_iter': 257, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 11/11 [00:00<00:00, 1282.20it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 704\n",
            "  Num epochs = 8\n",
            "  Total optimization steps = 176\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 22/22 [00:02<00:00,  7.47it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:03<00:00,  7.29it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:03<00:00,  7.28it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:02<00:00,  7.46it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:02<00:00,  7.48it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:02<00:00,  7.49it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:03<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:02<00:00,  7.35it/s]\n",
            "Epoch: 100%|██████████| 8/8 [00:23<00:00,  2.98s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:57:40,879] Trial 30 finished with value: 0.11240930933760482 and parameters: {'learning_rate': 3.0827536132512546e-05, 'num_epochs': 8, 'batch_size': 32, 'num_iterations': 11, 'max_iter': 257, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 5.732017386640804e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 480, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 15/15 [00:00<00:00, 1433.39it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 960\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 150\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.43it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.29it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:20<00:00,  4.09s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:58:22,796] Trial 31 finished with value: 0.12078774617067832 and parameters: {'learning_rate': 5.732017386640804e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 480, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 5.775157796063113e-05, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 19, 'max_iter': 414, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 19/19 [00:00<00:00, 1465.22it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1216\n",
            "  Num epochs = 4\n",
            "  Total optimization steps = 152\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 38/38 [00:05<00:00,  7.34it/s]\n",
            "Iteration: 100%|██████████| 38/38 [00:05<00:00,  7.33it/s]\n",
            "Iteration: 100%|██████████| 38/38 [00:05<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 38/38 [00:05<00:00,  7.23it/s]\n",
            "Epoch: 100%|██████████| 4/4 [00:20<00:00,  5.22s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:59:05,308] Trial 32 finished with value: 0.11769629125908876 and parameters: {'learning_rate': 5.775157796063113e-05, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 19, 'max_iter': 414, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 6.157251577345059e-05, 'num_epochs': 3, 'batch_size': 32, 'num_iterations': 17, 'max_iter': 461, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 17/17 [00:00<00:00, 605.94it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1088\n",
            "  Num epochs = 3\n",
            "  Total optimization steps = 102\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.33it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.32it/s]\n",
            "Epoch: 100%|██████████| 3/3 [00:13<00:00,  4.64s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 11:59:40,618] Trial 33 finished with value: 0.11279109339296998 and parameters: {'learning_rate': 6.157251577345059e-05, 'num_epochs': 3, 'batch_size': 32, 'num_iterations': 17, 'max_iter': 461, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 3.157479950712273e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 13, 'max_iter': 431, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 13/13 [00:00<00:00, 1411.86it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 832\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 130\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.32it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.39it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.24it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:17<00:00,  3.56s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:00:20,015] Trial 34 finished with value: 0.11460944550285772 and parameters: {'learning_rate': 3.157479950712273e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 13, 'max_iter': 431, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 1.4822767135242677e-05, 'num_epochs': 6, 'batch_size': 16, 'num_iterations': 16, 'max_iter': 279, 'solver': 'saga'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 1439.05it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 384\n",
            "  Total train batch size = 16\n",
            "Iteration: 100%|██████████| 64/64 [00:05<00:00, 12.39it/s]\n",
            "Iteration: 100%|██████████| 64/64 [00:05<00:00, 12.15it/s]\n",
            "Iteration: 100%|██████████| 64/64 [00:05<00:00, 12.39it/s]\n",
            "Iteration: 100%|██████████| 64/64 [00:05<00:00, 12.66it/s]\n",
            "Iteration: 100%|██████████| 64/64 [00:05<00:00, 12.53it/s]\n",
            "Iteration: 100%|██████████| 64/64 [00:05<00:00, 12.53it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:30<00:00,  5.15s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:01:12,338] Trial 35 finished with value: 0.10741576936436262 and parameters: {'learning_rate': 1.4822767135242677e-05, 'num_epochs': 6, 'batch_size': 16, 'num_iterations': 16, 'max_iter': 279, 'solver': 'saga'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 6.820974800850528e-05, 'num_epochs': 7, 'batch_size': 8, 'num_iterations': 7, 'max_iter': 54, 'solver': 'liblinear'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 7/7 [00:00<00:00, 1310.25it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 448\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 392\n",
            "  Total train batch size = 8\n",
            "Iteration: 100%|██████████| 56/56 [00:04<00:00, 13.67it/s]\n",
            "Iteration: 100%|██████████| 56/56 [00:04<00:00, 13.76it/s]\n",
            "Iteration: 100%|██████████| 56/56 [00:03<00:00, 14.16it/s]\n",
            "Iteration: 100%|██████████| 56/56 [00:04<00:00, 13.61it/s]\n",
            "Iteration: 100%|██████████| 56/56 [00:04<00:00, 13.61it/s]\n",
            "Iteration: 100%|██████████| 56/56 [00:04<00:00, 13.71it/s]\n",
            "Iteration: 100%|██████████| 56/56 [00:04<00:00, 13.87it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:28<00:00,  4.07s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:02:02,456] Trial 36 finished with value: 0.11762883403903748 and parameters: {'learning_rate': 6.820974800850528e-05, 'num_epochs': 7, 'batch_size': 8, 'num_iterations': 7, 'max_iter': 54, 'solver': 'liblinear'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 3.1730849440126924e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 11, 'max_iter': 372, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 11/11 [00:00<00:00, 1327.04it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 704\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 132\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 22/22 [00:02<00:00,  7.49it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:03<00:00,  7.29it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:03<00:00,  7.28it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:02<00:00,  7.45it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:02<00:00,  7.49it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:02<00:00,  7.48it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:17<00:00,  2.97s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:02:41,707] Trial 37 finished with value: 0.11343340300209007 and parameters: {'learning_rate': 3.1730849440126924e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 11, 'max_iter': 372, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 4.342759576341002e-05, 'num_epochs': 3, 'batch_size': 16, 'num_iterations': 15, 'max_iter': 331, 'solver': 'saga'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 15/15 [00:00<00:00, 1264.08it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 960\n",
            "  Num epochs = 3\n",
            "  Total optimization steps = 180\n",
            "  Total train batch size = 16\n",
            "Iteration: 100%|██████████| 60/60 [00:04<00:00, 12.44it/s]\n",
            "Iteration: 100%|██████████| 60/60 [00:04<00:00, 12.37it/s]\n",
            "Iteration: 100%|██████████| 60/60 [00:04<00:00, 12.31it/s]\n",
            "Epoch: 100%|██████████| 3/3 [00:14<00:00,  4.85s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:03:17,840] Trial 38 finished with value: 0.1123827392120075 and parameters: {'learning_rate': 4.342759576341002e-05, 'num_epochs': 3, 'batch_size': 16, 'num_iterations': 15, 'max_iter': 331, 'solver': 'saga'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 1.1698083563539123e-05, 'num_epochs': 1, 'batch_size': 4, 'num_iterations': 18, 'max_iter': 459, 'solver': 'liblinear'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 18/18 [00:00<00:00, 1459.11it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1152\n",
            "  Num epochs = 1\n",
            "  Total optimization steps = 288\n",
            "  Total train batch size = 4\n",
            "Iteration: 100%|██████████| 288/288 [00:20<00:00, 14.17it/s]\n",
            "Epoch: 100%|██████████| 1/1 [00:20<00:00, 20.33s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:03:59,461] Trial 39 finished with value: 0.10998641602033214 and parameters: {'learning_rate': 1.1698083563539123e-05, 'num_epochs': 1, 'batch_size': 4, 'num_iterations': 18, 'max_iter': 459, 'solver': 'liblinear'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 9.071956668616697e-05, 'num_epochs': 10, 'batch_size': 8, 'num_iterations': 13, 'max_iter': 292, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 13/13 [00:00<00:00, 1381.56it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 832\n",
            "  Num epochs = 10\n",
            "  Total optimization steps = 1040\n",
            "  Total train batch size = 8\n",
            "Iteration: 100%|██████████| 104/104 [00:07<00:00, 14.27it/s]\n",
            "Iteration: 100%|██████████| 104/104 [00:07<00:00, 14.18it/s]\n",
            "Iteration: 100%|██████████| 104/104 [00:07<00:00, 14.00it/s]\n",
            "Iteration: 100%|██████████| 104/104 [00:07<00:00, 13.66it/s]\n",
            "Iteration: 100%|██████████| 104/104 [00:07<00:00, 13.88it/s]\n",
            "Iteration: 100%|██████████| 104/104 [00:07<00:00, 14.37it/s]\n",
            "Iteration: 100%|██████████| 104/104 [00:07<00:00, 14.25it/s]\n",
            "Iteration: 100%|██████████| 104/104 [00:07<00:00, 13.80it/s]\n",
            "Iteration: 100%|██████████| 104/104 [00:07<00:00, 13.84it/s]\n",
            "Iteration: 100%|██████████| 104/104 [00:07<00:00, 13.98it/s]\n",
            "Epoch: 100%|██████████| 10/10 [01:14<00:00,  7.42s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:05:35,023] Trial 40 finished with value: 0.11674030436917035 and parameters: {'learning_rate': 9.071956668616697e-05, 'num_epochs': 10, 'batch_size': 8, 'num_iterations': 13, 'max_iter': 292, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 4.486857708663001e-05, 'num_epochs': 1, 'batch_size': 8, 'num_iterations': 5, 'max_iter': 94, 'solver': 'liblinear'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 5/5 [00:00<00:00, 1300.32it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 320\n",
            "  Num epochs = 1\n",
            "  Total optimization steps = 40\n",
            "  Total train batch size = 8\n",
            "Iteration: 100%|██████████| 40/40 [00:02<00:00, 13.71it/s]\n",
            "Epoch: 100%|██████████| 1/1 [00:02<00:00,  2.92s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:05:59,693] Trial 41 finished with value: 0.09363828560445897 and parameters: {'learning_rate': 4.486857708663001e-05, 'num_epochs': 1, 'batch_size': 8, 'num_iterations': 5, 'max_iter': 94, 'solver': 'liblinear'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 2.164613331618774e-05, 'num_epochs': 2, 'batch_size': 8, 'num_iterations': 16, 'max_iter': 112, 'solver': 'liblinear'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 1389.27it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 2\n",
            "  Total optimization steps = 256\n",
            "  Total train batch size = 8\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 13.74it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 13.66it/s]\n",
            "Epoch: 100%|██████████| 2/2 [00:18<00:00,  9.35s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:06:39,946] Trial 42 finished with value: 0.10922668586081244 and parameters: {'learning_rate': 2.164613331618774e-05, 'num_epochs': 2, 'batch_size': 8, 'num_iterations': 16, 'max_iter': 112, 'solver': 'liblinear'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 4.9414649653993725e-05, 'num_epochs': 3, 'batch_size': 8, 'num_iterations': 16, 'max_iter': 53, 'solver': 'liblinear'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 1261.66it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 3\n",
            "  Total optimization steps = 384\n",
            "  Total train batch size = 8\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 14.21it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 14.19it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:08<00:00, 14.37it/s]\n",
            "Epoch: 100%|██████████| 3/3 [00:26<00:00,  8.98s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:07:28,638] Trial 43 finished with value: 0.1128985083357707 and parameters: {'learning_rate': 4.9414649653993725e-05, 'num_epochs': 3, 'batch_size': 8, 'num_iterations': 16, 'max_iter': 53, 'solver': 'liblinear'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 3.175441456177642e-05, 'num_epochs': 5, 'batch_size': 8, 'num_iterations': 19, 'max_iter': 161, 'solver': 'liblinear'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 19/19 [00:00<00:00, 1464.20it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1216\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 760\n",
            "  Total train batch size = 8\n",
            "Iteration: 100%|██████████| 152/152 [00:10<00:00, 13.89it/s]\n",
            "Iteration: 100%|██████████| 152/152 [00:11<00:00, 13.68it/s]\n",
            "Iteration: 100%|██████████| 152/152 [00:11<00:00, 13.79it/s]\n",
            "Iteration: 100%|██████████| 152/152 [00:11<00:00, 13.73it/s]\n",
            "Iteration: 100%|██████████| 152/152 [00:11<00:00, 13.70it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:55<00:00, 11.05s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:08:45,278] Trial 44 finished with value: 0.11368700516759113 and parameters: {'learning_rate': 3.175441456177642e-05, 'num_epochs': 5, 'batch_size': 8, 'num_iterations': 19, 'max_iter': 161, 'solver': 'liblinear'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 7.287171139499745e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 105, 'solver': 'liblinear'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 14/14 [00:00<00:00, 1442.08it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 896\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 196\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.45it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.31it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.53it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.30it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.33it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:26<00:00,  3.81s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:09:33,617] Trial 45 finished with value: 0.10770249393069964 and parameters: {'learning_rate': 7.287171139499745e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 105, 'solver': 'liblinear'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 9.64368018301645e-05, 'num_epochs': 2, 'batch_size': 8, 'num_iterations': 17, 'max_iter': 142, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 17/17 [00:00<00:00, 1461.07it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1088\n",
            "  Num epochs = 2\n",
            "  Total optimization steps = 272\n",
            "  Total train batch size = 8\n",
            "Iteration: 100%|██████████| 136/136 [00:10<00:00, 13.60it/s]\n",
            "Iteration: 100%|██████████| 136/136 [00:10<00:00, 13.51it/s]\n",
            "Epoch: 100%|██████████| 2/2 [00:20<00:00, 10.04s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:10:15,022] Trial 46 finished with value: 0.11830437234097085 and parameters: {'learning_rate': 9.64368018301645e-05, 'num_epochs': 2, 'batch_size': 8, 'num_iterations': 17, 'max_iter': 142, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 7.461997074369397e-06, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 75, 'solver': 'liblinear'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 15/15 [00:00<00:00, 1329.16it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 960\n",
            "  Num epochs = 4\n",
            "  Total optimization steps = 120\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.42it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.36it/s]\n",
            "Epoch: 100%|██████████| 4/4 [00:16<00:00,  4.09s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:10:53,067] Trial 47 finished with value: 0.10530642443174812 and parameters: {'learning_rate': 7.461997074369397e-06, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 75, 'solver': 'liblinear'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 1.284435330985265e-05, 'num_epochs': 9, 'batch_size': 16, 'num_iterations': 18, 'max_iter': 500, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 18/18 [00:00<00:00, 1450.73it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1152\n",
            "  Num epochs = 9\n",
            "  Total optimization steps = 648\n",
            "  Total train batch size = 16\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 12.45it/s]\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 12.33it/s]\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 12.40it/s]\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 12.42it/s]\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 12.42it/s]\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 12.36it/s]\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 12.35it/s]\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 12.31it/s]\n",
            "Iteration: 100%|██████████| 72/72 [00:05<00:00, 12.30it/s]\n",
            "Epoch: 100%|██████████| 9/9 [00:52<00:00,  5.83s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:12:06,858] Trial 48 finished with value: 0.10887042443296654 and parameters: {'learning_rate': 1.284435330985265e-05, 'num_epochs': 9, 'batch_size': 16, 'num_iterations': 18, 'max_iter': 500, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 3.834086044823609e-06, 'num_epochs': 8, 'batch_size': 32, 'num_iterations': 20, 'max_iter': 206, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 20/20 [00:00<00:00, 1469.85it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1280\n",
            "  Num epochs = 8\n",
            "  Total optimization steps = 320\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 40/40 [00:05<00:00,  7.30it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:05<00:00,  7.47it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:05<00:00,  7.31it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:05<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:05<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:05<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:05<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 40/40 [00:05<00:00,  7.40it/s]\n",
            "Epoch: 100%|██████████| 8/8 [00:43<00:00,  5.46s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:13:12,228] Trial 49 finished with value: 0.1044180013999259 and parameters: {'learning_rate': 3.834086044823609e-06, 'num_epochs': 8, 'batch_size': 32, 'num_iterations': 20, 'max_iter': 206, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 1.8415238472389963e-05, 'num_epochs': 6, 'batch_size': 4, 'num_iterations': 12, 'max_iter': 393, 'solver': 'saga'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 12/12 [00:00<00:00, 655.83it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 768\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 1152\n",
            "  Total train batch size = 4\n",
            "Iteration: 100%|██████████| 192/192 [00:13<00:00, 14.42it/s]\n",
            "Iteration: 100%|██████████| 192/192 [00:13<00:00, 14.60it/s]\n",
            "Iteration: 100%|██████████| 192/192 [00:12<00:00, 14.84it/s]\n",
            "Iteration: 100%|██████████| 192/192 [00:13<00:00, 14.43it/s]\n",
            "Iteration: 100%|██████████| 192/192 [00:13<00:00, 14.72it/s]\n",
            "Iteration: 100%|██████████| 192/192 [00:13<00:00, 14.25it/s]\n",
            "Epoch: 100%|██████████| 6/6 [01:19<00:00, 13.21s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:14:52,982] Trial 50 finished with value: 0.10760602874167544 and parameters: {'learning_rate': 1.8415238472389963e-05, 'num_epochs': 6, 'batch_size': 4, 'num_iterations': 12, 'max_iter': 393, 'solver': 'saga'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 4.206131646965096e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 440, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 1461.81it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 224\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.38it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.19it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.21it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.16it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:30<00:00,  4.41s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:15:45,534] Trial 51 finished with value: 0.11950828433992518 and parameters: {'learning_rate': 4.206131646965096e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 440, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 5.07207941141536e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 17, 'max_iter': 472, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 17/17 [00:00<00:00, 1436.17it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1088\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 204\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.38it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.33it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.34it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.28it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.22it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:27<00:00,  4.65s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:16:35,073] Trial 52 finished with value: 0.11528722506330372 and parameters: {'learning_rate': 5.07207941141536e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 17, 'max_iter': 472, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 6.346355397803525e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 461, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 1467.31it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 160\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.17it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.27it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:22<00:00,  4.40s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:17:18,724] Trial 53 finished with value: 0.13631739572736523 and parameters: {'learning_rate': 6.346355397803525e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 461, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 9.962429431983652e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 423, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 15/15 [00:00<00:00, 1444.45it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 960\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 150\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.42it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.29it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:20<00:00,  4.09s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:18:00,909] Trial 54 finished with value: 0.12059674400136139 and parameters: {'learning_rate': 9.962429431983652e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 423, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 6.753405843209925e-05, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 79, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 14/14 [00:00<00:00, 846.34it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 896\n",
            "  Num epochs = 4\n",
            "  Total optimization steps = 112\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.43it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.32it/s]\n",
            "Epoch: 100%|██████████| 4/4 [00:15<00:00,  3.82s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:18:37,655] Trial 55 finished with value: 0.10169491525423728 and parameters: {'learning_rate': 6.753405843209925e-05, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 79, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 2.4938895307936435e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 18, 'max_iter': 235, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 18/18 [00:00<00:00, 1356.79it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1152\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 180\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.39it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.21it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.42it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:24<00:00,  4.93s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:19:24,016] Trial 56 finished with value: 0.11068963941318952 and parameters: {'learning_rate': 2.4938895307936435e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 18, 'max_iter': 235, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 3.629056923977512e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 17, 'max_iter': 358, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 17/17 [00:00<00:00, 1423.87it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1088\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 238\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.33it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.33it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.21it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.27it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:32<00:00,  4.66s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:20:18,047] Trial 57 finished with value: 0.11417019638043897 and parameters: {'learning_rate': 3.629056923977512e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 17, 'max_iter': 358, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 6.87716119420369e-05, 'num_epochs': 2, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 446, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 1449.06it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 2\n",
            "  Total optimization steps = 64\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.17it/s]\n",
            "Epoch: 100%|██████████| 2/2 [00:08<00:00,  4.41s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:20:48,225] Trial 58 finished with value: 0.11637817646130373 and parameters: {'learning_rate': 6.87716119420369e-05, 'num_epochs': 2, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 446, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 1.5533869451610587e-05, 'num_epochs': 6, 'batch_size': 8, 'num_iterations': 19, 'max_iter': 489, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 19/19 [00:00<00:00, 1475.15it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1216\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 912\n",
            "  Total train batch size = 8\n",
            "Iteration: 100%|██████████| 152/152 [00:10<00:00, 14.31it/s]\n",
            "Iteration: 100%|██████████| 152/152 [00:11<00:00, 13.75it/s]\n",
            "Iteration: 100%|██████████| 152/152 [00:10<00:00, 13.83it/s]\n",
            "Iteration: 100%|██████████| 152/152 [00:11<00:00, 13.69it/s]\n",
            "Iteration: 100%|██████████| 152/152 [00:10<00:00, 13.86it/s]\n",
            "Iteration: 100%|██████████| 152/152 [00:10<00:00, 13.84it/s]\n",
            "Epoch: 100%|██████████| 6/6 [01:05<00:00, 10.96s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:22:15,611] Trial 59 finished with value: 0.10718614718614718 and parameters: {'learning_rate': 1.5533869451610587e-05, 'num_epochs': 6, 'batch_size': 8, 'num_iterations': 19, 'max_iter': 489, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 2.4499816828980394e-05, 'num_epochs': 8, 'batch_size': 32, 'num_iterations': 13, 'max_iter': 400, 'solver': 'liblinear'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 13/13 [00:00<00:00, 623.03it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 832\n",
            "  Num epochs = 8\n",
            "  Total optimization steps = 208\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.33it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.33it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.40it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.46it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.37it/s]\n",
            "Epoch: 100%|██████████| 8/8 [00:28<00:00,  3.55s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:23:05,456] Trial 60 finished with value: 0.11060834590246355 and parameters: {'learning_rate': 2.4499816828980394e-05, 'num_epochs': 8, 'batch_size': 32, 'num_iterations': 13, 'max_iter': 400, 'solver': 'liblinear'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 4.0335556291436925e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 459, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 671.89it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 192\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.34it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.18it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.19it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:26<00:00,  4.41s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:23:53,781] Trial 61 finished with value: 0.12129900204002868 and parameters: {'learning_rate': 4.0335556291436925e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 459, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 6.262603288305611e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 451, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 15/15 [00:00<00:00, 1431.34it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 960\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 150\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.43it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.28it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:20<00:00,  4.09s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:24:35,590] Trial 62 finished with value: 0.1325683428957138 and parameters: {'learning_rate': 6.262603288305611e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 451, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 6.194935090450025e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 411, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 14/14 [00:00<00:00, 1268.06it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 896\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 140\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.45it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.34it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.32it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.54it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:18<00:00,  3.80s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:25:16,222] Trial 63 finished with value: 0.10152772765547936 and parameters: {'learning_rate': 6.194935090450025e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 411, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 5.391594610513569e-05, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 472, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 15/15 [00:00<00:00, 1367.89it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 960\n",
            "  Num epochs = 4\n",
            "  Total optimization steps = 120\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.45it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.35it/s]\n",
            "Epoch: 100%|██████████| 4/4 [00:16<00:00,  4.08s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:25:53,963] Trial 64 finished with value: 0.11954624781849914 and parameters: {'learning_rate': 5.391594610513569e-05, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 472, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 9.907361094288728e-05, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 17, 'max_iter': 315, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 17/17 [00:00<00:00, 1256.98it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1088\n",
            "  Num epochs = 4\n",
            "  Total optimization steps = 136\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.33it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.33it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.36it/s]\n",
            "Epoch: 100%|██████████| 4/4 [00:18<00:00,  4.63s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:26:34,141] Trial 65 finished with value: 0.10995812852721647 and parameters: {'learning_rate': 9.907361094288728e-05, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 17, 'max_iter': 315, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 3.3729514451690844e-05, 'num_epochs': 5, 'batch_size': 4, 'num_iterations': 16, 'max_iter': 424, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 1354.72it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 1280\n",
            "  Total train batch size = 4\n",
            "Iteration: 100%|██████████| 256/256 [00:18<00:00, 13.94it/s]\n",
            "Iteration: 100%|██████████| 256/256 [00:18<00:00, 13.86it/s]\n",
            "Iteration: 100%|██████████| 256/256 [00:18<00:00, 13.89it/s]\n",
            "Iteration: 100%|██████████| 256/256 [00:18<00:00, 13.92it/s]\n",
            "Iteration: 100%|██████████| 256/256 [00:17<00:00, 14.58it/s]\n",
            "Epoch: 100%|██████████| 5/5 [01:31<00:00, 18.25s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:28:26,662] Trial 66 finished with value: 0.1142940094841769 and parameters: {'learning_rate': 3.3729514451690844e-05, 'num_epochs': 5, 'batch_size': 4, 'num_iterations': 16, 'max_iter': 424, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 7.665975856048434e-05, 'num_epochs': 3, 'batch_size': 32, 'num_iterations': 18, 'max_iter': 474, 'solver': 'saga'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 18/18 [00:00<00:00, 1446.81it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1152\n",
            "  Num epochs = 3\n",
            "  Total optimization steps = 108\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.41it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.30it/s]\n",
            "Epoch: 100%|██████████| 3/3 [00:14<00:00,  4.92s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:29:03,243] Trial 67 finished with value: 0.11401239689589535 and parameters: {'learning_rate': 7.665975856048434e-05, 'num_epochs': 3, 'batch_size': 32, 'num_iterations': 18, 'max_iter': 474, 'solver': 'saga'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 5.1955561521355495e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 446, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 15/15 [00:00<00:00, 1440.52it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 960\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 210\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.46it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.39it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.29it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.31it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.24it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:28<00:00,  4.10s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:29:53,333] Trial 68 finished with value: 0.11291325773886417 and parameters: {'learning_rate': 5.1955561521355495e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 446, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 2.713833550887679e-05, 'num_epochs': 5, 'batch_size': 16, 'num_iterations': 9, 'max_iter': 383, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 9/9 [00:00<00:00, 1387.87it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 576\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 180\n",
            "  Total train batch size = 16\n",
            "Iteration: 100%|██████████| 36/36 [00:02<00:00, 12.44it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:02<00:00, 12.50it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:02<00:00, 12.48it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:02<00:00, 12.83it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:02<00:00, 12.77it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:14<00:00,  2.86s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:30:29,233] Trial 69 finished with value: 0.10909741799794156 and parameters: {'learning_rate': 2.713833550887679e-05, 'num_epochs': 5, 'batch_size': 16, 'num_iterations': 9, 'max_iter': 383, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 3.719582997643092e-05, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 17, 'max_iter': 95, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 17/17 [00:00<00:00, 1406.79it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1088\n",
            "  Num epochs = 4\n",
            "  Total optimization steps = 136\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.38it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.33it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.32it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.37it/s]\n",
            "Epoch: 100%|██████████| 4/4 [00:18<00:00,  4.63s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:31:09,408] Trial 70 finished with value: 0.11063238359972202 and parameters: {'learning_rate': 3.719582997643092e-05, 'num_epochs': 4, 'batch_size': 32, 'num_iterations': 17, 'max_iter': 95, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.13975625585923415.\n",
            "Trial: {'learning_rate': 7.411716784550214e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 455, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 683.43it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 192\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.18it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.18it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:26<00:00,  4.41s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:31:57,265] Trial 71 finished with value: 0.143246711581649 and parameters: {'learning_rate': 7.411716784550214e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 455, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 7.854422906222179e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 428, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 1449.12it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 192\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.38it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.18it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.18it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:26<00:00,  4.41s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:32:45,399] Trial 72 finished with value: 0.12339829869710349 and parameters: {'learning_rate': 7.854422906222179e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 428, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 6.240895146053163e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 483, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 14/14 [00:00<00:00, 1009.53it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 896\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 196\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.45it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.32it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.53it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.30it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.34it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:26<00:00,  3.81s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:33:33,559] Trial 73 finished with value: 0.11210100290179707 and parameters: {'learning_rate': 6.240895146053163e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 483, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 8.094995868841935e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 461, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 15/15 [00:00<00:00, 1422.28it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 960\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 180\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.41it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.28it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.30it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:24<00:00,  4.10s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:34:19,876] Trial 74 finished with value: 0.12904394012554324 and parameters: {'learning_rate': 8.094995868841935e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 461, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 5.222442487834684e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 453, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 15/15 [00:00<00:00, 1319.68it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 960\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 150\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.44it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.23it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.28it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:20<00:00,  4.10s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:35:01,796] Trial 75 finished with value: 0.11733278536936197 and parameters: {'learning_rate': 5.222442487834684e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 453, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 6.847527866068068e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 18, 'max_iter': 466, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 18/18 [00:00<00:00, 1413.07it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1152\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 216\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.39it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.28it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.21it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.42it/s]\n",
            "Iteration: 100%|██████████| 36/36 [00:04<00:00,  7.36it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:29<00:00,  4.93s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:35:52,762] Trial 76 finished with value: 0.11919223381612418 and parameters: {'learning_rate': 6.847527866068068e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 18, 'max_iter': 466, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 8.117582495672508e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 13, 'max_iter': 492, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 13/13 [00:00<00:00, 1427.90it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 832\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 156\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.32it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.38it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.44it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:21<00:00,  3.55s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:36:35,667] Trial 77 finished with value: 0.11780608266181439 and parameters: {'learning_rate': 8.117582495672508e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 13, 'max_iter': 492, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 1.9930686636788494e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 17, 'max_iter': 438, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 17/17 [00:00<00:00, 1441.75it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1088\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 170\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.33it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.32it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 34/34 [00:04<00:00,  7.29it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:23<00:00,  4.64s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:37:20,289] Trial 78 finished with value: 0.10640589324947229 and parameters: {'learning_rate': 1.9930686636788494e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 17, 'max_iter': 438, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 3.9668157226375474e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 416, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 15/15 [00:00<00:00, 1238.57it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 960\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 180\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.43it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.34it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.28it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.31it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:24<00:00,  4.10s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:38:06,571] Trial 79 finished with value: 0.11602521395992416 and parameters: {'learning_rate': 3.9668157226375474e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 416, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 7.822078740804485e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 372, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 15/15 [00:00<00:00, 1406.23it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 960\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 210\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.44it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.28it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.31it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.23it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:28<00:00,  4.10s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:38:56,726] Trial 80 finished with value: 0.12281488121918423 and parameters: {'learning_rate': 7.822078740804485e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 372, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 9.979684512636686e-05, 'num_epochs': 8, 'batch_size': 8, 'num_iterations': 16, 'max_iter': 450, 'solver': 'liblinear'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 1302.02it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 8\n",
            "  Total optimization steps = 1024\n",
            "  Total train batch size = 8\n",
            "Iteration: 100%|██████████| 128/128 [00:08<00:00, 15.24it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 13.75it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 13.72it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 13.72it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 13.54it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 13.83it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 14.11it/s]\n",
            "Iteration: 100%|██████████| 128/128 [00:09<00:00, 13.77it/s]\n",
            "Epoch: 100%|██████████| 8/8 [01:13<00:00,  9.19s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:40:31,934] Trial 81 finished with value: 0.10949391171993911 and parameters: {'learning_rate': 9.979684512636686e-05, 'num_epochs': 8, 'batch_size': 8, 'num_iterations': 16, 'max_iter': 450, 'solver': 'liblinear'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 5.613248021815504e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 500, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 14/14 [00:00<00:00, 1439.40it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 896\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 168\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.45it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.32it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.54it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.30it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:22<00:00,  3.80s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:41:16,205] Trial 82 finished with value: 0.12837837837837837 and parameters: {'learning_rate': 5.613248021815504e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 500, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 5.534031567993354e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 499, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 14/14 [00:00<00:00, 1438.90it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 896\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 168\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.44it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.32it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.52it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.30it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:22<00:00,  3.81s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:42:00,495] Trial 83 finished with value: 0.11936132201875838 and parameters: {'learning_rate': 5.534031567993354e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 499, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 2.9150055069882496e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 481, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 14/14 [00:00<00:00, 1444.11it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 896\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 140\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.09it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.31it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.52it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:19<00:00,  3.84s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:42:41,002] Trial 84 finished with value: 0.11509937703945416 and parameters: {'learning_rate': 2.9150055069882496e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 481, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 4.221394907751326e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 459, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 16/16 [00:00<00:00, 1453.08it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 1024\n",
            "  Num epochs = 5\n",
            "  Total optimization steps = 160\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.39it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.19it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.34it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 32/32 [00:04<00:00,  7.26it/s]\n",
            "Epoch: 100%|██████████| 5/5 [00:21<00:00,  4.40s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:43:24,411] Trial 85 finished with value: 0.12727944800394284 and parameters: {'learning_rate': 4.221394907751326e-05, 'num_epochs': 5, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 459, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 4.4892140817566154e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 466, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 15/15 [00:00<00:00, 1426.31it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 960\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 180\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.44it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.28it/s]\n",
            "Iteration: 100%|██████████| 30/30 [00:04<00:00,  7.30it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:24<00:00,  4.10s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:44:10,637] Trial 86 finished with value: 0.11625381393184052 and parameters: {'learning_rate': 4.4892140817566154e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 15, 'max_iter': 466, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 7.795480047533884e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 13, 'max_iter': 489, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 13/13 [00:00<00:00, 1438.72it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 832\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 182\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.32it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.39it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.45it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.24it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:24<00:00,  3.56s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:44:57,149] Trial 87 finished with value: 0.12868061646410223 and parameters: {'learning_rate': 7.795480047533884e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 13, 'max_iter': 489, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 8.24141932137681e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 13, 'max_iter': 484, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 13/13 [00:00<00:00, 1267.99it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 832\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 182\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.32it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.40it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.23it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.44it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.24it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:24<00:00,  3.56s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:45:43,689] Trial 88 finished with value: 0.12637427591913938 and parameters: {'learning_rate': 8.24141932137681e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 13, 'max_iter': 484, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 3.753218181555604e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 466, 'solver': 'saga'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 14/14 [00:00<00:00, 638.38it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 896\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 196\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.42it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.32it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.53it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.30it/s]\n",
            "Iteration: 100%|██████████| 28/28 [00:03<00:00,  7.33it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:26<00:00,  3.81s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:46:32,286] Trial 89 finished with value: 0.12363306702929346 and parameters: {'learning_rate': 3.753218181555604e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 14, 'max_iter': 466, 'solver': 'saga'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 6.48891281656082e-05, 'num_epochs': 7, 'batch_size': 4, 'num_iterations': 11, 'max_iter': 491, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 11/11 [00:00<00:00, 1423.90it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 704\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 1232\n",
            "  Total train batch size = 4\n",
            "Iteration: 100%|██████████| 176/176 [00:12<00:00, 13.90it/s]\n",
            "Iteration: 100%|██████████| 176/176 [00:12<00:00, 14.05it/s]\n",
            "Iteration: 100%|██████████| 176/176 [00:12<00:00, 13.96it/s]\n",
            "Iteration: 100%|██████████| 176/176 [00:12<00:00, 13.92it/s]\n",
            "Iteration: 100%|██████████| 176/176 [00:12<00:00, 13.77it/s]\n",
            "Iteration: 100%|██████████| 176/176 [00:12<00:00, 13.97it/s]\n",
            "Iteration: 100%|██████████| 176/176 [00:12<00:00, 13.85it/s]\n",
            "Epoch: 100%|██████████| 7/7 [01:28<00:00, 12.65s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:48:22,509] Trial 90 finished with value: 0.11328012308875854 and parameters: {'learning_rate': 6.48891281656082e-05, 'num_epochs': 7, 'batch_size': 4, 'num_iterations': 11, 'max_iter': 491, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 7.993307558636686e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 12, 'max_iter': 480, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 12/12 [00:00<00:00, 1414.33it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 768\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 168\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.52it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.32it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.45it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.39it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.26it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.29it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:22<00:00,  3.26s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:49:06,731] Trial 91 finished with value: 0.12808319066641305 and parameters: {'learning_rate': 7.993307558636686e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 12, 'max_iter': 480, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 7.774242643120651e-05, 'num_epochs': 8, 'batch_size': 32, 'num_iterations': 12, 'max_iter': 477, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 12/12 [00:00<00:00, 1327.10it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 768\n",
            "  Num epochs = 8\n",
            "  Total optimization steps = 192\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.48it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.37it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.31it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.44it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.39it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.24it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.36it/s]\n",
            "Epoch: 100%|██████████| 8/8 [00:26<00:00,  3.27s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:49:54,477] Trial 92 finished with value: 0.1137393556097804 and parameters: {'learning_rate': 7.774242643120651e-05, 'num_epochs': 8, 'batch_size': 32, 'num_iterations': 12, 'max_iter': 477, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 5.712078264368515e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 11, 'max_iter': 457, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 11/11 [00:00<00:00, 1474.88it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 704\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 154\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 22/22 [00:02<00:00,  7.47it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:03<00:00,  7.28it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:03<00:00,  7.28it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:02<00:00,  7.46it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:02<00:00,  7.48it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:02<00:00,  7.45it/s]\n",
            "Iteration: 100%|██████████| 22/22 [00:03<00:00,  7.26it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:20<00:00,  2.98s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:50:36,941] Trial 93 finished with value: 0.11386639676113361 and parameters: {'learning_rate': 5.712078264368515e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 11, 'max_iter': 457, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 9.968562107763408e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 12, 'max_iter': 434, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 12/12 [00:00<00:00, 1302.17it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 768\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 144\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.48it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.31it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.44it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.38it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.24it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:19<00:00,  3.26s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:51:18,139] Trial 94 finished with value: 0.1325242379856316 and parameters: {'learning_rate': 9.968562107763408e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 12, 'max_iter': 434, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 9.097825915215124e-05, 'num_epochs': 6, 'batch_size': 16, 'num_iterations': 12, 'max_iter': 436, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 12/12 [00:00<00:00, 1295.44it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 768\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 288\n",
            "  Total train batch size = 16\n",
            "Iteration: 100%|██████████| 48/48 [00:03<00:00, 12.37it/s]\n",
            "Iteration: 100%|██████████| 48/48 [00:03<00:00, 12.37it/s]\n",
            "Iteration: 100%|██████████| 48/48 [00:03<00:00, 12.41it/s]\n",
            "Iteration: 100%|██████████| 48/48 [00:03<00:00, 12.49it/s]\n",
            "Iteration: 100%|██████████| 48/48 [00:03<00:00, 12.45it/s]\n",
            "Iteration: 100%|██████████| 48/48 [00:03<00:00, 12.27it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:23<00:00,  3.88s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:52:02,794] Trial 95 finished with value: 0.10139376949500532 and parameters: {'learning_rate': 9.097825915215124e-05, 'num_epochs': 6, 'batch_size': 16, 'num_iterations': 12, 'max_iter': 436, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 7.755741647515062e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 10, 'max_iter': 499, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 10/10 [00:00<00:00, 1387.74it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 640\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 140\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 20/20 [00:02<00:00,  7.42it/s]\n",
            "Iteration: 100%|██████████| 20/20 [00:02<00:00,  7.42it/s]\n",
            "Iteration: 100%|██████████| 20/20 [00:02<00:00,  7.28it/s]\n",
            "Iteration: 100%|██████████| 20/20 [00:02<00:00,  7.47it/s]\n",
            "Iteration: 100%|██████████| 20/20 [00:02<00:00,  7.33it/s]\n",
            "Iteration: 100%|██████████| 20/20 [00:02<00:00,  7.43it/s]\n",
            "Iteration: 100%|██████████| 20/20 [00:02<00:00,  7.49it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:18<00:00,  2.70s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:52:43,153] Trial 96 finished with value: 0.11808966454174939 and parameters: {'learning_rate': 7.755741647515062e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 10, 'max_iter': 499, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 4.7674013630062436e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 12, 'max_iter': 448, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 12/12 [00:00<00:00, 1368.34it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 768\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 144\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.47it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.28it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.44it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.38it/s]\n",
            "Iteration: 100%|██████████| 24/24 [00:03<00:00,  7.24it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:19<00:00,  3.27s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:53:24,434] Trial 97 finished with value: 0.11425390881951121 and parameters: {'learning_rate': 4.7674013630062436e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 12, 'max_iter': 448, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 6.310877724866444e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 13, 'max_iter': 475, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 13/13 [00:00<00:00, 1279.98it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 832\n",
            "  Num epochs = 7\n",
            "  Total optimization steps = 182\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.36it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.32it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.39it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.44it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.24it/s]\n",
            "Epoch: 100%|██████████| 7/7 [00:24<00:00,  3.55s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:54:10,713] Trial 98 finished with value: 0.1322623828647925 and parameters: {'learning_rate': 6.310877724866444e-05, 'num_epochs': 7, 'batch_size': 32, 'num_iterations': 13, 'max_iter': 475, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "Trial: {'learning_rate': 6.161283049183468e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 13, 'max_iter': 431, 'solver': 'lbfgs'}\n",
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 13/13 [00:00<00:00, 1426.82it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 832\n",
            "  Num epochs = 6\n",
            "  Total optimization steps = 156\n",
            "  Total train batch size = 32\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.35it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.27it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.31it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.38it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.25it/s]\n",
            "Iteration: 100%|██████████| 26/26 [00:03<00:00,  7.43it/s]\n",
            "Epoch: 100%|██████████| 6/6 [00:21<00:00,  3.55s/it]\n",
            "Applying column mapping to evaluation dataset\n",
            "***** Running evaluation *****\n",
            "[I 2023-11-12 12:54:53,881] Trial 99 finished with value: 0.12624217887375783 and parameters: {'learning_rate': 6.161283049183468e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 13, 'max_iter': 431, 'solver': 'lbfgs'}. Best is trial 71 with value: 0.143246711581649.\n",
            "/tmp/ipykernel_123082/213641716.py:23: ExperimentalWarning: plot_param_importances is experimental (supported from v2.2.0). The interface can change in the future.\n",
            "  plot_param_importances(best_run.backend)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best Run: BestRun(run_id='71', objective=0.143246711581649, hyperparameters={'learning_rate': 7.411716784550214e-05, 'num_epochs': 6, 'batch_size': 32, 'num_iterations': 16, 'max_iter': 455, 'solver': 'lbfgs'}, backend=<optuna.study.study.Study object at 0x7f5a0c0f5a10>)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "setfit_hyperparameter_tuning()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def eval_train_setfit(full_pos_label=True, store_files=False, use_setfithead=False):\n",
        "    train_data, dev_data = prepare_wice_data()\n",
        "    val_dataset = Dataset.from_pandas(dev_data)\n",
        "\n",
        "    if full_pos_label:\n",
        "      # Take amount of train labels corresponding to support (imbalanced compared to no support) as the total number of samples.\n",
        "      nsamples = len(train_data[train_data['label'] == 1]) # ~4427 rows\n",
        "      train_dataset_full = Dataset.from_pandas(train_data)\n",
        "      train_dataset = sample_dataset(train_dataset_full, num_samples=nsamples)\n",
        "    else:\n",
        "      # Use same datasets as hypertuning\n",
        "      train_dataset_full = pd.read_csv(f'{save_dir}/tune_train.csv')\n",
        "      train_dataset = Dataset.from_pandas(train_dataset_full)\n",
        "    \n",
        "\n",
        "    # Instantiate with best hypertuned model parameters\n",
        "    trainer = SetFitTrainer(\n",
        "        model_init=model_init(use_setfithead=use_setfithead),\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        column_mapping={\"evidence\": \"text\", \"label\": \"label\"},\n",
        "        metric=compute_metrics,\n",
        "    )\n",
        "    best_run = load_run()\n",
        "    print(f\"Initialize model using hypertuned parameters: {best_run}\\n\\n\")\n",
        "    trainer.apply_hyperparameters(best_run.hyperparameters, final_model=True)\n",
        "\n",
        "    if use_setfithead:\n",
        "        # Train and evaluate\n",
        "        trainer.freeze() # Freeze the head\n",
        "        trainer.train() # Train only the body\n",
        "\n",
        "        # Unfreeze the head and unfreeze the body -> end-to-end training\n",
        "        trainer.unfreeze(keep_body_frozen=False)\n",
        "\n",
        "        trainer.train(\n",
        "            num_epochs=25, # The number of epochs to train the head or the whole model (body and head)\n",
        "            batch_size=16,\n",
        "            body_learning_rate=1e-5, # The body's learning rate\n",
        "            learning_rate=1e-2, # The head's learning rate\n",
        "            l2_weight=0.0, # Weight decay on **both** the body and head. If `None`, will use 0.01.\n",
        "        )\n",
        "    else:\n",
        "        # Train and evaluate\n",
        "        trainer.train()\n",
        "\n",
        "    # Get predictions\n",
        "    with torch.no_grad():\n",
        "        dev_data['predictions'] = trainer.model.predict(x_test=dev_data['evidence'], as_numpy=True, show_progress_bar=True)\n",
        "        print(f\"Metrics full-dev set: {compute_metrics(dev_data['label'].to_list(), dev_data['predictions'].to_list())}\")\n",
        "\n",
        "    # Save used datasets\n",
        "    if store_files:\n",
        "        train_df = Dataset.to_pandas(train_dataset)\n",
        "        train_df.to_csv(f'{save_dir}/val_train.csv', index=False)\n",
        "        dev_data.to_csv(f'{save_dir}/val_dev.csv', index=False)\n",
        "        trainer.model._save_pretrained(save_directory=save_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sklearn classification head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialize model using hypertuned parameters: BestRun(run_id='82', objective=0.7336765104307775, hyperparameters={'learning_rate': 7.359481282349892e-05, 'num_epochs': 1, 'batch_size': 4, 'num_iterations': 5, 'max_iter': 270, 'solver': 'saga'}, backend=<optuna.study.study.Study object at 0x7fb1f61fee50>)\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 5/5 [00:00<00:00, 1283.84it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 320\n",
            "  Num epochs = 1\n",
            "  Total optimization steps = 80\n",
            "  Total train batch size = 4\n",
            "Iteration: 100%|██████████| 80/80 [00:05<00:00, 14.25it/s]\n",
            "Epoch: 100%|██████████| 1/1 [00:05<00:00,  5.62s/it]\n",
            "Batches: 100%|██████████| 1304/1304 [00:19<00:00, 66.51it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics full-dev set: {'accuracy': 0.7676258992805756, 'f1': 0.11555312157721798, 'precision': 0.06670179135932561, 'recall': 0.43178717598908595}\n"
          ]
        }
      ],
      "source": [
        "eval_train_setfit(full_pos_label=False, store_files=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialize model using hypertuned parameters: BestRun(run_id='82', objective=0.7336765104307775, hyperparameters={'learning_rate': 7.359481282349892e-05, 'num_epochs': 1, 'batch_size': 4, 'num_iterations': 5, 'max_iter': 270, 'solver': 'saga'}, backend=<optuna.study.study.Study object at 0x7fb1f5e92ad0>)\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 5/5 [00:01<00:00,  2.92it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 88540\n",
            "  Num epochs = 1\n",
            "  Total optimization steps = 22135\n",
            "  Total train batch size = 4\n",
            "Iteration: 100%|██████████| 22135/22135 [25:57<00:00, 14.22it/s]\n",
            "Epoch: 100%|██████████| 1/1 [25:57<00:00, 1557.01s/it]\n",
            "Batches: 100%|██████████| 1304/1304 [00:19<00:00, 65.77it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics full-dev set: {'accuracy': 0.03515587529976019, 'f1': 0.06792382893944307, 'precision': 0.03515587529976019, 'recall': 1.0}\n"
          ]
        }
      ],
      "source": [
        "eval_train_setfit(full_pos_label=True, store_files=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SetFithead classification head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialize model using hypertuned parameters: BestRun(run_id='82', objective=0.7336765104307775, hyperparameters={'learning_rate': 7.359481282349892e-05, 'num_epochs': 1, 'batch_size': 4, 'num_iterations': 5, 'max_iter': 270, 'solver': 'saga'}, backend=<optuna.study.study.Study object at 0x7fb3800bda50>)\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
            "Applying column mapping to training dataset\n",
            "Generating Training Pairs: 100%|██████████| 5/5 [00:00<00:00, 1281.33it/s]\n",
            "***** Running training *****\n",
            "  Num examples = 320\n",
            "  Num epochs = 1\n",
            "  Total optimization steps = 80\n",
            "  Total train batch size = 4\n",
            "Iteration: 100%|██████████| 80/80 [00:05<00:00, 13.88it/s]\n",
            "Epoch: 100%|██████████| 1/1 [00:05<00:00,  5.77s/it]\n",
            "Applying column mapping to training dataset\n",
            "The `max_length` is `None`. Using the maximum acceptable length according to the current model body: 512.\n",
            "Epoch: 100%|██████████| 25/25 [00:17<00:00,  1.47it/s]\n",
            "Batches: 100%|██████████| 1304/1304 [00:18<00:00, 70.76it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics dev set: {'accuracy': 0.5875779376498801, 'f1': 0.10361722089023247, 'precision': 0.056094808126410836, 'recall': 0.6780354706684857}\n"
          ]
        }
      ],
      "source": [
        "eval_train_setfit(full_pos_label=False, store_files=True, use_setfithead=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at SpanBERT/spanbert-base-cased and are newly initialized: ['classifier.weight', 'bert.pooler.dense.weight', 'classifier.bias', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "##### Setup BERT model #####\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_name = \"SpanBERT/spanbert-base-cased\"\n",
        "model = BertForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
        "#                                           do_lower_case=True, \n",
        "#                                           output_attentions=False, \n",
        "#                                           output_hidden_states=False, \n",
        "#                                           return_dict=False)\n",
        "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "model.to(device)\n",
        "\n",
        "##### Set up static variables #####\n",
        "save_dir = os.path.join(dir_path, \"models\", \"bert\", \"wice_classifier\")\n",
        "batch_size = 32\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BERT train & eval on WiCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def prepare_dataset(tokenizer, data: Dataset):\n",
        "#     def tokenize_function(examples):\n",
        "#         return tokenizer(examples[\"evidence\"], \n",
        "#                         padding=\"max_length\", \n",
        "#                         truncation=True,\n",
        "#                         return_tensors = 'pt')\n",
        "\n",
        "#     tokenized_dataset = data.map(tokenize_function, batched=True)\n",
        "#     tokenized_dataset = tokenized_dataset.remove_columns([\"evidence\"])\n",
        "#     tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
        "#     tokenized_dataset.set_format(\"torch\")\n",
        "#     return tokenized_dataset\n",
        "\n",
        "# def load_bert_data(tokenizer):\n",
        "#     train_path = f\"{data_path}/wice_train\"\n",
        "#     dev_path = f\"{data_path}/wice_dev\"\n",
        "\n",
        "#     if not os.path.isdir(train_path):\n",
        "#         train_data, dev_data = prepare_wice_data()\n",
        "#         tokenized_train_dataset = prepare_dataset(tokenizer, train_data)\n",
        "#         tokenized_train_dataset.save_to_disk(train_path)\n",
        "#         tokenized_dev_dataset = prepare_dataset(tokenizer, dev_data)\n",
        "#         tokenized_dev_dataset.save_to_disk(dev_path)\n",
        "#     else:\n",
        "#         tokenized_train_dataset = load_from_disk(train_path)\n",
        "#         tokenized_dev_dataset = load_from_disk(dev_path)\n",
        "\n",
        "#     return tokenized_train_dataset, tokenized_dev_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##### Prepare Data ######\n",
        "# train_dataset, val_dataset= load_bert_data(tokenizer)\n",
        "# train_dataset = subsample_train(Dataset.to_pandas(train_dataset))\n",
        "\n",
        "# train_dataset.set_format('torch')\n",
        "# val_dataset.set_format('torch')\n",
        "\n",
        "# train_dataloader = DataLoader(train_dataset,batch_size = batch_size)\n",
        "# eval_dataloader = DataLoader(val_dataset, batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "##### Training #####\n",
        "# optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
        "\n",
        "# num_epochs = 3\n",
        "# # Total number of training steps is [number of batches] x [number of epochs].\n",
        "# num_training_steps = num_epochs * len(train_dataloader)\n",
        "# lr_scheduler = get_linear_schedule_with_warmup(\n",
        "#     optimizer=optimizer, \n",
        "#     num_warmup_steps=0, \n",
        "#     num_training_steps=num_training_steps\n",
        "# )\n",
        "\n",
        "# # #freeze few layers for better training\n",
        "# # for param in model.bert.encoder.layer[0:6].parameters():\n",
        "# #     param.requires_grad=False\n",
        "# # for param in model.bert.embeddings.parameters():\n",
        "# #     param.requires_grad=False\n",
        "\n",
        "# progress_bar = tqdm(range(num_training_steps))\n",
        "# model.train()\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     for batch in train_dataset:\n",
        "#         batch = {k: v.to(device) for k, v in batch.items() if k != 'label'}\n",
        "#         outputs = model(**batch)\n",
        "#         loss = outputs.loss\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         lr_scheduler.step()\n",
        "#         optimizer.zero_grad()\n",
        "#         progress_bar.update(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8850/8850 [1:34:49<00:00,  1.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'f1': 0.1321985815602837} - {'accuracy': 0.6332134292565947}\n"
          ]
        }
      ],
      "source": [
        "##### Evaluation #####\n",
        "# progress_bar = tqdm(range(len(eval_dataloader)))\n",
        "# metric = evaluate.load(\"f1\")\n",
        "# metric2 = evaluate.load(\"accuracy\")\n",
        "# model.eval()\n",
        "\n",
        "# for batch in eval_dataloader:\n",
        "#     batch = {k: v.to(device) for k, v in batch.items()}\n",
        "#     with torch.no_grad():\n",
        "#         outputs = model(**batch)\n",
        "#     logits = outputs.logits\n",
        "#     predictions = torch.argmax(logits, dim=-1)\n",
        "#     metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "#     metric2.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "#     progress_bar.update(1)\n",
        "# print(f\"{metric.compute()} - {metric2.compute()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Span-BERT train & eval on WiCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim</th>\n",
              "      <th>evidence</th>\n",
              "      <th>indices</th>\n",
              "      <th>claim_spans</th>\n",
              "      <th>start_idx</th>\n",
              "      <th>end_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Arnold is currently the publisher and editoria...</td>\n",
              "      <td>[(meta data) TITLE: About Us – Media Play News...</td>\n",
              "      <td>[5, 15, 17]</td>\n",
              "      <td>[Media Play News is the voice of the home ente...</td>\n",
              "      <td>[116, 1648, 1810]</td>\n",
              "      <td>[180, 1716, 1960]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Tozzer library itself holds over 260,000 v...</td>\n",
              "      <td>[(meta data) TITLE: Mission &amp; History | About ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>He appeared in the 2016 Grammy-nominated docum...</td>\n",
              "      <td>[(meta data) TITLE: Steve Aoki 'I'll Sleep Whe...</td>\n",
              "      <td>[0, 2, 9, 11, 12, 14, 20, 23, 24]</td>\n",
              "      <td>[(meta data) TITLE: Steve Aoki 'I'll Sleep Whe...</td>\n",
              "      <td>[0, 166, 404, 446, 534, 1063, 2528, 3332, 3498]</td>\n",
              "      <td>[103, 208, 419, 533, 859, 1256, 2929, 3497, 3750]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This further decreased to 41.3 % in 2016 , mai...</td>\n",
              "      <td>[(meta data) TITLE: Behind the God-swapping in...</td>\n",
              "      <td>[3, 73, 115]</td>\n",
              "      <td>[(meta data) PUBLISHED DATETIME: 2016-06-27T19...</td>\n",
              "      <td>[188, 2492, 7402]</td>\n",
              "      <td>[240, 2598, 7564]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The band's third album, \"Emotive\", was release...</td>\n",
              "      <td>[(meta data) TITLE: A Perfect Circle Album Pre...</td>\n",
              "      <td>[2, 8, 29]</td>\n",
              "      <td>[(meta data) PUBLISHED DATETIME: 2004-10-19 14...</td>\n",
              "      <td>[129, 602, 3643]</td>\n",
              "      <td>[177, 720, 3691]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               claim  \\\n",
              "0  Arnold is currently the publisher and editoria...   \n",
              "1  The Tozzer library itself holds over 260,000 v...   \n",
              "2  He appeared in the 2016 Grammy-nominated docum...   \n",
              "3  This further decreased to 41.3 % in 2016 , mai...   \n",
              "4  The band's third album, \"Emotive\", was release...   \n",
              "\n",
              "                                            evidence  \\\n",
              "0  [(meta data) TITLE: About Us – Media Play News...   \n",
              "1  [(meta data) TITLE: Mission & History | About ...   \n",
              "2  [(meta data) TITLE: Steve Aoki 'I'll Sleep Whe...   \n",
              "3  [(meta data) TITLE: Behind the God-swapping in...   \n",
              "4  [(meta data) TITLE: A Perfect Circle Album Pre...   \n",
              "\n",
              "                             indices  \\\n",
              "0                        [5, 15, 17]   \n",
              "1                                 []   \n",
              "2  [0, 2, 9, 11, 12, 14, 20, 23, 24]   \n",
              "3                       [3, 73, 115]   \n",
              "4                         [2, 8, 29]   \n",
              "\n",
              "                                         claim_spans  \\\n",
              "0  [Media Play News is the voice of the home ente...   \n",
              "1                                                 []   \n",
              "2  [(meta data) TITLE: Steve Aoki 'I'll Sleep Whe...   \n",
              "3  [(meta data) PUBLISHED DATETIME: 2016-06-27T19...   \n",
              "4  [(meta data) PUBLISHED DATETIME: 2004-10-19 14...   \n",
              "\n",
              "                                         start_idx  \\\n",
              "0                                [116, 1648, 1810]   \n",
              "1                                               []   \n",
              "2  [0, 166, 404, 446, 534, 1063, 2528, 3332, 3498]   \n",
              "3                                [188, 2492, 7402]   \n",
              "4                                 [129, 602, 3643]   \n",
              "\n",
              "                                             end_idx  \n",
              "0                                  [180, 1716, 1960]  \n",
              "1                                                 []  \n",
              "2  [103, 208, 419, 533, 859, 1256, 2929, 3497, 3750]  \n",
              "3                                  [240, 2598, 7564]  \n",
              "4                                   [177, 720, 3691]  "
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def span_indices(row_data):\n",
        "    indices = sorted(set(idx for sublist in row_data[\"supporting_sentences\"] for idx in sublist))\n",
        "    return indices\n",
        "\n",
        "def claim_spans(row_data):\n",
        "    claims, start_idx, end_idx = [], [], []\n",
        "    for idx in row_data['indices']:\n",
        "        claim_worthy = row_data['evidence'][idx]\n",
        "        start = len(' '.join(row_data['evidence'][:idx]))\n",
        "\n",
        "        claims.append(claim_worthy)\n",
        "        start_idx.append(start)\n",
        "        end_idx.append(start + len(claim_worthy))\n",
        "    return claims, start_idx, end_idx\n",
        "    \n",
        "\n",
        "df_train = pd.read_json(f\"{data_path}/train.jsonl\", lines=True)\n",
        "df_train['indices'] = df_train.apply(span_indices, axis=1)\n",
        "df_train.drop(columns=['label', 'supporting_sentences', 'meta'], inplace=True)\n",
        "df_train[['claim_spans', 'start_idx', 'end_idx']] = df_train.apply(claim_spans, axis=1, result_type='expand')\n",
        "\n",
        "df_dev = pd.read_json(f\"{data_path}/dev.jsonl\", lines=True)\n",
        "df_dev['indices'] = df_dev.apply(span_indices, axis=1)\n",
        "df_dev.drop(columns=['label', 'supporting_sentences', 'meta'], inplace=True)\n",
        "df_dev[['claim_spans', 'start_idx', 'end_idx']]= df_dev.apply(claim_spans, axis=1, result_type='expand')\n",
        "\n",
        "df_dev.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://www.kaggle.com/code/anasofiauzsoy/tweet-sentiment-extraction-with-tf2-spanbert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_len = 512\n",
        "\n",
        "class WiceExample:\n",
        "    def __init__(self, evidence, start_char_idx, end_char_idx, claim_spans):\n",
        "        self.evidence = evidence\n",
        "        self.start_char_idx = start_char_idx\n",
        "        self.end_char_idx = end_char_idx\n",
        "        self.claim_spans = claim_spans\n",
        "        self.skip = False\n",
        "\n",
        "    def preprocess(self):\n",
        "        # Merge the text in evidence and text of claim spans\n",
        "        evidence_txt = \" \".join(self.evidence)\n",
        "        # span_text = \" \".join(self.claim_spans)\n",
        "\n",
        "        # Mark the character indexes in text that are in answer\n",
        "        is_char_in_span = [0] * len(evidence_txt)\n",
        "        for start_idx, end_idx in zip(self.start_char_idx, self.end_char_idx):\n",
        "            for idx in range(start_idx, end_idx):\n",
        "                is_char_in_span[idx] = 1\n",
        "\n",
        "        # Tokenize text\n",
        "        tokenized_text = tokenizer.encode_plus(evidence_txt, return_offsets_mapping=True, max_length = max_len, truncation=True)\n",
        "\n",
        "        # Find tokens that were created from answer characters\n",
        "        span_token_idx = []\n",
        "        for idx, (start, end) in enumerate(tokenized_text.offset_mapping):\n",
        "            if sum(is_char_in_span[start:end]) > 0:\n",
        "                span_token_idx.append(idx)\n",
        "\n",
        "        # Find start and end token index for tokens from answer\n",
        "        start_token_idx = span_token_idx[0]\n",
        "        end_token_idx = span_token_idx[-1]\n",
        "\n",
        "        # Pad/truncate and create attention masks.\n",
        "        padding_length = max_len - len(tokenized_text.input_ids)\n",
        "        if padding_length >= 0:\n",
        "            input_ids = tokenized_text.input_ids + ([0] * padding_length)\n",
        "            attention_mask = tokenized_text.attention_mask + ([0] * padding_length)\n",
        "            token_type_ids = tokenized_text.token_type_ids + ([0] * padding_length)\n",
        "        elif padding_length < 0:\n",
        "            input_ids = tokenized_text.input_ids[:padding_length]\n",
        "            attention_mask = tokenized_text.attention_mask[:padding_length]\n",
        "            token_type_ids = tokenized_text.token_type_ids[:padding_length]\n",
        "\n",
        "        self.input_ids = input_ids\n",
        "        self.token_type_ids = token_type_ids\n",
        "        self.attention_mask = attention_mask\n",
        "\n",
        "        self.start_token_idx = start_token_idx\n",
        "        self.end_token_idx = end_token_idx\n",
        "        self.context_token_to_char = tokenized_text.offset_mapping\n",
        "\n",
        "def create_wice_examples(data):\n",
        "    wice_examples = []\n",
        "    failed = 0\n",
        "    for _, row in data.iterrows():\n",
        "        try: ## turn the data into WiCEExample objects\n",
        "            w_example = WiceExample(evidence=row['evidence'], \n",
        "                                    start_char_idx=row['start_idx'], \n",
        "                                    end_char_idx=row['end_idx'], \n",
        "                                    claim_spans=row['claim_spans']\n",
        "                                    )\n",
        "            w_example.preprocess()\n",
        "            wice_examples.append(w_example)\n",
        "        except:\n",
        "            failed += 1 \n",
        "    print(f\"{failed} points failed to process, {len(wice_examples)} training points created.\")\n",
        "    return wice_examples\n",
        "\n",
        "def create_inputs_targets(wice_examples):\n",
        "    dataset_dict = {\n",
        "        \"input_ids\": [],\n",
        "        \"token_type_ids\": [],\n",
        "        \"attention_mask\": [],\n",
        "        \"start_token_idx\": [],\n",
        "        \"end_token_idx\": [],\n",
        "    }\n",
        "    for item in wice_examples:\n",
        "        if item.skip == False:\n",
        "            for key in dataset_dict:\n",
        "                dataset_dict[key].append(getattr(item, key))\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\n",
        "\n",
        "    x = [dataset_dict[\"input_ids\"], dataset_dict[\"token_type_ids\"], dataset_dict[\"attention_mask\"]]\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "372 points failed to process, 888 training points created.\n",
            "77 points failed to process, 272 training points created.\n"
          ]
        }
      ],
      "source": [
        "train_examples = create_wice_examples(df_train)\n",
        "x_train, y_train = create_inputs_targets(train_examples)\n",
        "\n",
        "dev_examples = create_wice_examples(df_dev)\n",
        "x_eval, y_eval = create_inputs_targets(dev_examples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class WiceSpanBERT(nn.Module):\n",
        "    def __init__(self, model, max_len):\n",
        "        super(WiceSpanBERT, self).__init__()\n",
        "        \n",
        "        self.model = model\n",
        "\n",
        "        # QA Model layers\n",
        "        self.embedding = nn.encoder.get_input_embeddings()\n",
        "        \n",
        "        self.start_logits = nn.Sequential(\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Conv1d(self.config.hidden_size, 128, kernel_size=2, padding=1),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Conv1d(128, 64, kernel_size=2, padding=1),\n",
        "            nn.Linear(64 * max_len, 1),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        \n",
        "        self.end_logits = nn.Sequential(\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Conv1d(self.config.hidden_size, 128, kernel_size=2, padding=1),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Conv1d(128, 64, kernel_size=2, padding=1),\n",
        "            nn.Linear(64 * max_len, 1),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        \n",
        "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
        "        embedding = self.embedding(input_ids)\n",
        "        outputs = self.encoder(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
        "        sequence_output = outputs.last_hidden_state\n",
        "\n",
        "        start_logits = self.start_logits(embedding.transpose(1, 2))\n",
        "        end_logits = self.end_logits(embedding.transpose(1, 2))\n",
        "\n",
        "        start_probs = torch.nn.functional.softmax(start_logits, dim=-1)\n",
        "        end_probs = torch.nn.functional.softmax(end_logits, dim=-1)\n",
        "\n",
        "        return start_probs, end_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'torch.nn' has no attribute 'encoder'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/home/venky/Grounding-LM/helpers/wice_support_model.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcubone.kbs.uni-hannover.de/home/venky/Grounding-LM/helpers/wice_support_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m WiCeSpan_Model(model, max_len)\n",
            "\u001b[1;32m/home/venky/Grounding-LM/helpers/wice_support_model.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcubone.kbs.uni-hannover.de/home/venky/Grounding-LM/helpers/wice_support_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcubone.kbs.uni-hannover.de/home/venky/Grounding-LM/helpers/wice_support_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# QA Model layers\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcubone.kbs.uni-hannover.de/home/venky/Grounding-LM/helpers/wice_support_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mencoder\u001b[39m.\u001b[39mget_input_embeddings()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcubone.kbs.uni-hannover.de/home/venky/Grounding-LM/helpers/wice_support_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstart_logits \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcubone.kbs.uni-hannover.de/home/venky/Grounding-LM/helpers/wice_support_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     nn\u001b[39m.\u001b[39mDropout(\u001b[39m0.3\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcubone.kbs.uni-hannover.de/home/venky/Grounding-LM/helpers/wice_support_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     nn\u001b[39m.\u001b[39mConv1d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mhidden_size, \u001b[39m128\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcubone.kbs.uni-hannover.de/home/venky/Grounding-LM/helpers/wice_support_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     nn\u001b[39m.\u001b[39mFlatten()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcubone.kbs.uni-hannover.de/home/venky/Grounding-LM/helpers/wice_support_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcubone.kbs.uni-hannover.de/home/venky/Grounding-LM/helpers/wice_support_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend_logits \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcubone.kbs.uni-hannover.de/home/venky/Grounding-LM/helpers/wice_support_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     nn\u001b[39m.\u001b[39mDropout(\u001b[39m0.3\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcubone.kbs.uni-hannover.de/home/venky/Grounding-LM/helpers/wice_support_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     nn\u001b[39m.\u001b[39mConv1d(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mhidden_size, \u001b[39m128\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcubone.kbs.uni-hannover.de/home/venky/Grounding-LM/helpers/wice_support_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     nn\u001b[39m.\u001b[39mFlatten()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcubone.kbs.uni-hannover.de/home/venky/Grounding-LM/helpers/wice_support_model.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m )\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'encoder'"
          ]
        }
      ],
      "source": [
        "model = WiCeSpan_Model(model, max_len)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "grounding",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
